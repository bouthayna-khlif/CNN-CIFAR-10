{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "name": "CNN_cifar_ES_(1) (1).ipynb",
      "private_outputs": true,
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "0nVi5b6K_6Gk"
      },
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras.datasets import cifar10\n",
        "from tensorflow.keras import layers, models\n",
        "import keras.models\n",
        "from keras.models import Sequential\n",
        "#from keras.layers.normalization import BatchNormalization\n",
        "from tensorflow.keras.layers import Conv2D, MaxPooling2D,BatchNormalization, Activation\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "import matplotlib.pyplot as plt\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split\n",
        "from keras.optimizers import Adam"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "z-noH-ZB_7g8"
      },
      "source": [
        "def visualize_data(images, categories, class_names):\n",
        "    fig = plt.figure(figsize=(14, 6))\n",
        "    fig.patch.set_facecolor('white')\n",
        "    for i in range(3 * 7):\n",
        "        plt.subplot(3, 7, i+1)\n",
        "        plt.xticks([])\n",
        "        plt.yticks([])\n",
        "        plt.imshow(images[i])\n",
        "        class_index = categories[i].argmax()\n",
        "        plt.xlabel(class_names[class_index])\n",
        "    plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0XNw_RFF_7mS"
      },
      "source": [
        "class_names = ['airplane', 'automobile', 'bird', 'cat', 'deer', 'dog', 'frog', 'horse', 'ship', 'truck']\n",
        "num_classes = len(class_names)\n",
        "\n",
        " #split the data into test, validation and train \n",
        " \n",
        "(x_train, y_train), (x_test, y_test) = cifar10.load_data()\n",
        "\n",
        "X= np.concatenate((x_train,x_test))\n",
        "Y= np.concatenate((y_train,y_test))\n",
        "\n",
        "x_train, x_test, y_train, y_test = train_test_split( X, Y, test_size=0.2, random_state=1)\n",
        "x_train, x_val, y_train, y_val = train_test_split(x_train, y_train, test_size=0.2, random_state=1)\n",
        "\n",
        "\n",
        "\n",
        "x_train = x_train / 255.0\n",
        "y_train = to_categorical(y_train, num_classes)\n",
        "\n",
        "x_val = x_val / 255.0\n",
        "y_val = to_categorical(y_val, num_classes)\n",
        "\n",
        "x_test = x_test / 255.0\n",
        "y_test = to_categorical(y_test, num_classes)\n",
        "\n",
        "#visualize_data(x_train, y_train, class_names)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7h7VHpHF_7qH"
      },
      "source": [
        "print(x_train.shape[0], 'train samples')\n",
        "print(x_test.shape[0], 'test samples')\n",
        "print(x_val.shape[0], 'validation samples')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "q0JJA5KeLFdF"
      },
      "source": [
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "\n",
        "nsamples = 38400\n",
        "nclasses=10\n",
        "features = np.array( [ x_train[i][0].flatten() for i in range(nsamples)] )\n",
        "labels   = np.array( [ x_train[i][1] for i in range(nsamples)])\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uT7DLwPeQZZS"
      },
      "source": [
        "# plt.hist(y_train,[0,1,2,3,4,5,6,7,8,9])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uinhL4XtKAHS"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TZ1tqXS3_7sn"
      },
      "source": [
        "def create_model():\n",
        "    model = models.Sequential()\n",
        "    model.add(layers.Conv2D(32, (3, 3), activation='relu', padding='same', input_shape=(32, 32, 3)))\n",
        "    model.add(BatchNormalization())\n",
        "    model.add(layers.Conv2D(32, (3, 3), activation='relu', padding='same'))\n",
        "    model.add(BatchNormalization())\n",
        "    model.add(layers.MaxPool2D((2,2)))\n",
        "\n",
        "    model.add(layers.Conv2D(64, (3, 3), activation='relu', padding='same',))\n",
        "    model.add(BatchNormalization())\n",
        "    model.add(layers.Conv2D(64, (3, 3), activation='relu', padding='same',))\n",
        "    model.add(BatchNormalization())\n",
        "    model.add(layers.MaxPool2D((2,2)))\n",
        "\n",
        "    model.add(layers.Conv2D(128, (3, 3), activation='relu', padding='same',))\n",
        "    model.add(BatchNormalization())\n",
        "    model.add(layers.Conv2D(128, (3, 3), activation='relu', padding='same',))\n",
        "    model.add(BatchNormalization())\n",
        "    model.add(layers.MaxPool2D((2,2)))\n",
        "   \n",
        "   \n",
        "    model.add(layers.Flatten())\n",
        "  \n",
        "    model.add(layers.Dropout(0.2))\n",
        "    \n",
        "    model.add(layers.Dense(128, activation='relu'))\n",
        "    # model.add(layers.Dropout(0.2))\n",
        "    model.add(layers.Dense(10, activation='softmax'))\n",
        "    \n",
        "    model.compile(optimizer='adam',\n",
        "                  loss='categorical_crossentropy',\n",
        "                  metrics=['accuracy'])\n",
        "\n",
        "    return model"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "k3qfK4T2AtMl"
      },
      "source": [
        "m_no_aug = create_model()\n",
        "m_no_aug.summary()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7Yr7MTCUA-s_"
      },
      "source": [
        "from keras.callbacks import EarlyStopping\n",
        "from keras.callbacks import ModelCheckpoint\n",
        "from keras.callbacks import ReduceLROnPlateau\n",
        "from keras.callbacks import Callback\n",
        "import math"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZDBKg356lSfI"
      },
      "source": [
        "# from google.colab import drive\n",
        "# drive.mount('/content/drive')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WCo1GtpNppt1"
      },
      "source": [
        "\n",
        "initial_learning_rate = 0.001\n",
        "def lr_step_decay(epoch, lr):\n",
        "    drop_rate = 0.2\n",
        "    epochs_drop = 20\n",
        "    return initial_learning_rate * math.pow(drop_rate, math.floor(epoch/epochs_drop))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VewRGJPMpl_D"
      },
      "source": [
        "\n",
        "batch_size = 16\n",
        "epochs = 1500\n",
        "\n",
        "# earlyStopping = tf.keras.callbacks.EarlyStopping(monitor='val_loss', patience=10, verbose=1, mode='auto',min_delta=0.01)\n",
        "# mcp_save = tf.keras.callbacks.ModelCheckpoint('/content/drive/MyDrive/archive/mod/minff-{epoch:02d}-{val_loss:.2f}.h5', save_best_only=True, monitor='val_loss', mode='min',verbose=1,save_weights_only=False)\n",
        "# reduce_lr_loss =tf.keras.callbacks.LearningRateScheduler(lr_step_decay, verbose=1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ppKFn5xOrh5j"
      },
      "source": [
        "reduce_lr_loss =tf.keras.callbacks.LearningRateScheduler(lr_step_decay, verbose=1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Y9B5_qJBIj7b"
      },
      "source": [
        "# def scheduler(epoch, lr):\n",
        "#     if epoch < 10:\n",
        "#        return lr\n",
        "#     else:\n",
        "#        return lr * 0.2"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "P-w-fppaIkDw"
      },
      "source": [
        "# rs=tf.keras.callbacks.LearningRateScheduler(scheduler, verbose=1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Uze4Myo760MA"
      },
      "source": [
        "es = EarlyStopping(monitor='val_accuracy', mode='max', min_delta=0.001,verbose=1, patience=20)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mi268-A_60Nn"
      },
      "source": [
        "mc = ModelCheckpoint('best_model.h5', monitor='val_accuracy', mode='max', verbose=1,save_best_only=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dTv21UVvy8JA"
      },
      "source": [
        "# reduce_lr = ReduceLROnPlateau(monitor='val_loss', factor=0.1, verbose=1,\n",
        "#                               patience=5,  min_delta=0.0001,  cooldown=0 ,min_lr=0, mode='min')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BIbUSeAhrfO-"
      },
      "source": [
        "# from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint\n",
        "\n",
        "# keras_callbacks   = [\n",
        "#       EarlyStopping(monitor='val_loss', patience=30, mode='min', min_delta=0.0001, verbose=1),\n",
        "#       ModelCheckpoint(checkpoint_path, monitor='val_loss', save_best_only=True, mode='min',verbose=1)\n",
        "# ]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "L0mkfoRW_7w7"
      },
      "source": [
        "batch_size = 32\n",
        "\n",
        "history_no_aug = m_no_aug.fit(\n",
        "    x_train, y_train,\n",
        "    epochs=2000, batch_size=batch_size,\n",
        "    validation_data=(x_val, y_val),\n",
        "    verbose=1,  \n",
        "    callbacks=[es, mc,reduce_lr_loss] )\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "J8xc4oZBsIWr"
      },
      "source": [
        "# load a saved model\n",
        "from keras.models import load_model\n",
        "saved_model = load_model('best_model.h5')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mBcvIHG1FsPU"
      },
      "source": [
        "# m_no_aug.save('modelcnn.h5')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LC0xGx-fCHww"
      },
      "source": [
        "_, train_acc = m_no_aug.evaluate(x_train, y_train, verbose=0)\n",
        "_, test_acc = m_no_aug.evaluate(x_test, y_test, verbose=0)\n",
        "print('Train: %.3f, Test: %.3f' % (train_acc, test_acc))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "__Y_nDdnBU6L"
      },
      "source": [
        " \n",
        "loss_no_aug, acc_no_aug = m_no_aug.evaluate(x_test,  y_test)\n",
        "\n",
        "print(f\"Testing on {len(x_test)} images, the results are\\n Accuracy: {acc_no_aug } | Loss: {loss_no_aug}\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yQOVTOPVy6FR"
      },
      "source": [
        " \n",
        "loss_no_aug_sav, acc_no_aug_sav = saved_model.evaluate(x_test,  y_test)\n",
        "\n",
        "print(f\"Testing on {len(x_test)} images, the results are\\n Accuracy: {acc_no_aug } | Loss: {loss_no_aug}\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kMbjWwl1-ltY"
      },
      "source": [
        "\n",
        "\n",
        "fig = plt.figure()\n",
        "fig.patch.set_facecolor('white')\n",
        "plt.plot(history_no_aug.history['accuracy'],\n",
        "         label='train accuracy',\n",
        "         c='dodgerblue', ls='-')\n",
        "plt.plot(history_no_aug.history['val_accuracy'],\n",
        "         label='validation accuracy',\n",
        "         c='dodgerblue', ls='--')\n",
        "\n",
        "plt.xlabel('Epoch')\n",
        "plt.ylabel('Accuracy')\n",
        "plt.legend(loc='lower right')\n",
        "plt.show()\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "fig = plt.figure()\n",
        "fig.patch.set_facecolor('white')\n",
        "plt.plot(history_no_aug.history['loss'],\n",
        "         label='train loss',\n",
        "         c='dodgerblue', ls='-')\n",
        "plt.plot(history_no_aug.history['val_loss'],\n",
        "         label='validation loss',\n",
        "         c='dodgerblue', ls='--')\n",
        "\n",
        "plt.xlabel('Epoch')\n",
        "plt.ylabel('Loss')\n",
        "plt.legend(loc='upper right')\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "y-mJ1AEHQHxa"
      },
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "\n",
        "def make_confusion_matrix(cf,\n",
        "                          group_names=None,\n",
        "                          categories='auto',\n",
        "                          count=True,\n",
        "                          percent=True,\n",
        "                          cbar=True,\n",
        "                          xyticks=True,\n",
        "                          xyplotlabels=True,\n",
        "                          sum_stats=True,\n",
        "                          figsize=(15,15),\n",
        "                          cmap='Blues',\n",
        "                          title=None):\n",
        "    '''\n",
        "    This function will make a pretty plot of an sklearn Confusion Matrix cm using a Seaborn heatmap visualization.\n",
        "    Arguments\n",
        "    ---------\n",
        "    cf:            confusion matrix to be passed in\n",
        "    group_names:   List of strings that represent the labels row by row to be shown in each square.\n",
        "    categories:    List of strings containing the categories to be displayed on the x,y axis. Default is 'auto'\n",
        "    count:         If True, show the raw number in the confusion matrix. Default is True.\n",
        "    normalize:     If True, show the proportions for each category. Default is True.\n",
        "    cbar:          If True, show the color bar. The cbar values are based off the values in the confusion matrix.\n",
        "                   Default is True.\n",
        "    xyticks:       If True, show x and y ticks. Default is True.\n",
        "    xyplotlabels:  If True, show 'True Label' and 'Predicted Label' on the figure. Default is True.\n",
        "    sum_stats:     If True, display summary statistics below the figure. Default is True.\n",
        "    figsize:       Tuple representing the figure size. Default will be the matplotlib rcParams value.\n",
        "    cmap:          Colormap of the values displayed from matplotlib.pyplot.cm. Default is 'Blues'\n",
        "                   See http://matplotlib.org/examples/color/colormaps_reference.html\n",
        "                   \n",
        "    title:         Title for the heatmap. Default is None.\n",
        "    '''\n",
        "\n",
        "\n",
        "    # CODE TO GENERATE TEXT INSIDE EACH SQUARE\n",
        "    blanks = ['' for i in range(cf.size)]\n",
        "\n",
        "    if group_names and len(group_names)==cf.size:\n",
        "        group_labels = [\"{}\\n\".format(value*10) for value in group_names]\n",
        "    else:\n",
        "        group_labels = blanks\n",
        "\n",
        "    if count:\n",
        "        group_counts = [\"{0:0.0f}\\n\".format(value*10) for value in cf.flatten()]\n",
        "    else:\n",
        "        group_counts = blanks\n",
        "\n",
        "    if percent:\n",
        "        group_percentages = [\"{0:.3}\".format(value*10*100) for value in cf.flatten()/np.sum(cf)]\n",
        "    else:\n",
        "        group_percentages = blanks\n",
        "\n",
        "    box_labels = [f\"{v1}{v2}{v3}\".strip() for v1, v2, v3 in zip(group_labels,group_counts,group_percentages)]\n",
        "    box_labels = np.asarray(box_labels).reshape(cf.shape[0],cf.shape[1])\n",
        "\n",
        "\n",
        "    # CODE TO GENERATE SUMMARY STATISTICS & TEXT FOR SUMMARY STATS\n",
        "    if sum_stats:\n",
        "        #Accuracy is sum of diagonal divided by total observations\n",
        "        accuracy  = np.trace(cf) / float(np.sum(cf))\n",
        "\n",
        "        #if it is a binary confusion matrix, show some more stats\n",
        "        if len(cf)==4:\n",
        "            #Metrics for Binary Confusion Matrices\n",
        "            precision = cf[1,1] / sum(cf[:,1])\n",
        "            recall    = cf[1,1] / sum(cf[1,:])\n",
        "            f1_score  = 2*precision*recall / (precision + recall)\n",
        "            stats_text = \"\\n\\nAccuracy={:0.4f}\\nPrecision={:0.4f}\\nRecall={:0.4f}\\nF1 Score={:0.4f}\".format(\n",
        "                accuracy,precision,recall,f1_score)\n",
        "        else:\n",
        "            stats_text = \"\\n\\nAccuracy={:0.4f}\".format(accuracy)\n",
        "    else:\n",
        "        stats_text = \"\"\n",
        "\n",
        "\n",
        "    # SET FIGURE PARAMETERS ACCORDING TO OTHER ARGUMENTS\n",
        "    if figsize==None:\n",
        "        #Get default figure size if not set\n",
        "        figsize = plt.rcParams.get('figure.figsize')\n",
        "\n",
        "    if xyticks==False:\n",
        "        #Do not show categories if xyticks is False\n",
        "        categories=False\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "    ax = plt.figure()\n",
        "\n",
        "    label_font = {'size':'20'}\n",
        "    # MAKE THE HEATMAP VISUALIZATION\n",
        "    plt.figure(figsize=figsize)\n",
        "    sns.set(font_scale=1.5)\n",
        "    sns.heatmap(cf,annot=box_labels,fmt=\"\",cmap=cmap,cbar=cbar,xticklabels=categories,yticklabels=categories)\n",
        "\n",
        "    if xyplotlabels:\n",
        "        plt.ylabel('Predicted label' , fontdict=label_font);\n",
        "        plt.xlabel('True label', fontdict=label_font);\n",
        "        # plt.ylabel('True label')\n",
        "        # plt.xlabel('Predicted label' + stats_text)\n",
        "    else:\n",
        "        plt.xlabel(stats_text)\n",
        "    \n",
        "    if title:\n",
        "        plt.title(title)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "  "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Cb4VNeOEQIBY"
      },
      "source": [
        "model1= m_no_aug\n",
        "y_pred = model1.predict(x_test) \n",
        "import numpy as np\n",
        "Y_pred = np.argmax(y_pred, 1) \n",
        "Y_test = np.argmax(y_test, 1) "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yxhnY5bYQIMY"
      },
      "source": [
        "import sklearn\n",
        "mat = sklearn.metrics.confusion_matrix(Y_test, Y_pred) # Confusion matrix\n",
        "lab=['airplane', 'automobile', 'bird', 'cat', 'deer', 'dog', 'frog', 'horse', 'ship', 'truck']"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SUVmagutQ1yr"
      },
      "source": [
        "make_confusion_matrix(mat,\n",
        "                          group_names=None,\n",
        "                          categories=lab,\n",
        "                          count=False,\n",
        "                          percent=True,\n",
        "                          cbar=True,\n",
        "                          xyticks=True,\n",
        "                          xyplotlabels=True,\n",
        "                          sum_stats=True,\n",
        "                          figsize=(14,14),\n",
        "                          cmap='Blues',\n",
        "                          title=None)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wqrvFOt4xIZ0"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ETslkvbP_77_"
      },
      "source": [
        "width_shift = 3/32\n",
        "height_shift = 3/32\n",
        "flip = True\n",
        "\n",
        "datagen = ImageDataGenerator(\n",
        "    horizontal_flip=flip,\n",
        "    \n",
        "    width_shift_range=width_shift,\n",
        "    height_shift_range=height_shift,\n",
        "    )\n",
        "datagen.fit(x_train)\n",
        "\n",
        "it = datagen.flow(x_train, y_train, shuffle=False)\n",
        "batch_images, batch_labels = next(it)\n",
        "visualize_data(batch_images, batch_labels, class_names)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "s2k0RSCn-7wE"
      },
      "source": [
        "mc1 = ModelCheckpoint('best_model_augmented.h5', 'val_accuracy', mode='max', verbose=1,save_best_only=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IBNMKyn7_7-3"
      },
      "source": [
        "m_aug = create_model()\n",
        "datagen.fit(x_train)\n",
        "\n",
        "history_aug = m_aug.fit(\n",
        "    datagen.flow(x_train, y_train, batch_size=batch_size),\n",
        "    epochs=2500,\n",
        "    validation_data=(x_val, y_val),\n",
        "    verbose=1,  \n",
        "    callbacks=[es, mc1,reduce_lr_loss])\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "P9y65XB1E8iz"
      },
      "source": [
        "loss_aug, acc_aug = m_aug.evaluate(x_test,y_test)\n",
        "\n",
        "print(f\"Testing on {len(x_test)} images, the results are\\n Accuracy: {acc_aug } | Loss: {loss_aug}\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EYAIcgiVI4QW"
      },
      "source": [
        "# load a saved model\n",
        "from keras.models import load_model\n",
        "saved_model_aug = load_model('/content/best_model_augmented.h5')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Vda8XLb-uGz5"
      },
      "source": [
        "loss_aug, acc_aug = saved_model_aug.evaluate(x_test,y_test)\n",
        "\n",
        "print(f\"Testing on {len(x_test)} images, the results are\\n Accuracy: {acc_aug } | Loss: {loss_aug}\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JXpceAYiidqJ"
      },
      "source": [
        ""
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ncZagbAc2oUJ"
      },
      "source": [
        "fig = plt.figure()\n",
        "fig.patch.set_facecolor('white')\n",
        "\n",
        "plt.plot(history_aug.history['accuracy'],\n",
        "         label='train accuracy augmented',\n",
        "         c='dodgerblue', ls='-')\n",
        "plt.plot(history_aug.history['val_accuracy'],\n",
        "         label='validation accuracy augmented',\n",
        "         c='orange',ls='--')\n",
        "\n",
        "plt.xlabel('Epoch')\n",
        "plt.ylabel('Accuracy')\n",
        "plt.legend(loc='lower right')\n",
        "plt.show()\n",
        "\n",
        "fig = plt.figure()\n",
        "fig.patch.set_facecolor('white')\n",
        "plt.plot(history_no_aug.history['accuracy'],\n",
        "         label='train accuracy',\n",
        "         c='dodgerblue', ls='-')\n",
        "plt.plot(history_no_aug.history['val_accuracy'],\n",
        "         label='validation accuracy',\n",
        "         c='orange', ls='--')\n",
        "\n",
        "plt.xlabel('Epoch')\n",
        "plt.ylabel('Accuracy')\n",
        "plt.legend(loc='lower right')\n",
        "plt.show()\n",
        "\n",
        "\n",
        "\n",
        "fig = plt.figure()\n",
        "fig.patch.set_facecolor('white')\n",
        "\n",
        "\n",
        "plt.plot(history_aug.history['loss'],\n",
        "         label='train loss augmented',\n",
        "         c='dodgerblue', ls='-')\n",
        "plt.plot(history_aug.history['val_loss'],\n",
        "         label='validation loss augmented',\n",
        "         c='orange',ls='--')\n",
        "plt.xlabel('Epoch')\n",
        "plt.ylabel('Loss')\n",
        "plt.legend(loc='upper right')\n",
        "plt.show()\n",
        "\n",
        "\n",
        "fig = plt.figure()\n",
        "fig.patch.set_facecolor('white')\n",
        "plt.plot(history_no_aug.history['loss'],\n",
        "         label='train loss',\n",
        "         c='dodgerblue', ls='-')\n",
        "plt.plot(history_no_aug.history['val_loss'],\n",
        "         label='validation loss',\n",
        "         c='orange', ls='--')\n",
        "\n",
        "plt.xlabel('Epoch')\n",
        "plt.ylabel('Loss')\n",
        "plt.legend(loc='upper right')\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "K8NkQMM5gZhw"
      },
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "\n",
        "def make_confusion_matrix(cf,\n",
        "                          group_names=None,\n",
        "                          categories='auto',\n",
        "                          count=True,\n",
        "                          percent=True,\n",
        "                          cbar=True,\n",
        "                          xyticks=True,\n",
        "                          xyplotlabels=True,\n",
        "                          sum_stats=True,\n",
        "                          figsize=(15,15),\n",
        "                          cmap='Blues',\n",
        "                          title=None):\n",
        "    '''\n",
        "    This function will make a pretty plot of an sklearn Confusion Matrix cm using a Seaborn heatmap visualization.\n",
        "    Arguments\n",
        "    ---------\n",
        "    cf:            confusion matrix to be passed in\n",
        "    group_names:   List of strings that represent the labels row by row to be shown in each square.\n",
        "    categories:    List of strings containing the categories to be displayed on the x,y axis. Default is 'auto'\n",
        "    count:         If True, show the raw number in the confusion matrix. Default is True.\n",
        "    normalize:     If True, show the proportions for each category. Default is True.\n",
        "    cbar:          If True, show the color bar. The cbar values are based off the values in the confusion matrix.\n",
        "                   Default is True.\n",
        "    xyticks:       If True, show x and y ticks. Default is True.\n",
        "    xyplotlabels:  If True, show 'True Label' and 'Predicted Label' on the figure. Default is True.\n",
        "    sum_stats:     If True, display summary statistics below the figure. Default is True.\n",
        "    figsize:       Tuple representing the figure size. Default will be the matplotlib rcParams value.\n",
        "    cmap:          Colormap of the values displayed from matplotlib.pyplot.cm. Default is 'Blues'\n",
        "                   See http://matplotlib.org/examples/color/colormaps_reference.html\n",
        "                   \n",
        "    title:         Title for the heatmap. Default is None.\n",
        "    '''\n",
        "\n",
        "\n",
        "    # CODE TO GENERATE TEXT INSIDE EACH SQUARE\n",
        "    blanks = ['' for i in range(cf.size)]\n",
        "\n",
        "    if group_names and len(group_names)==cf.size:\n",
        "        group_labels = [\"{}\\n\".format(value*10) for value in group_names]\n",
        "    else:\n",
        "        group_labels = blanks\n",
        "\n",
        "    if count:\n",
        "        group_counts = [\"{0:0.0f}\\n\".format(value*10) for value in cf.flatten()]\n",
        "    else:\n",
        "        group_counts = blanks\n",
        "\n",
        "    if percent:\n",
        "        group_percentages = [\"{0:.3}\".format(value*10*100) for value in cf.flatten()/np.sum(cf)]\n",
        "    else:\n",
        "        group_percentages = blanks\n",
        "\n",
        "    box_labels = [f\"{v1}{v2}{v3}\".strip() for v1, v2, v3 in zip(group_labels,group_counts,group_percentages)]\n",
        "    box_labels = np.asarray(box_labels).reshape(cf.shape[0],cf.shape[1])\n",
        "\n",
        "\n",
        "    # CODE TO GENERATE SUMMARY STATISTICS & TEXT FOR SUMMARY STATS\n",
        "    if sum_stats:\n",
        "        #Accuracy is sum of diagonal divided by total observations\n",
        "        accuracy  = np.trace(cf) / float(np.sum(cf))\n",
        "\n",
        "        #if it is a binary confusion matrix, show some more stats\n",
        "        if len(cf)==4:\n",
        "            #Metrics for Binary Confusion Matrices\n",
        "            precision = cf[1,1] / sum(cf[:,1])\n",
        "            recall    = cf[1,1] / sum(cf[1,:])\n",
        "            f1_score  = 2*precision*recall / (precision + recall)\n",
        "            stats_text = \"\\n\\nAccuracy={:0.4f}\\nPrecision={:0.4f}\\nRecall={:0.4f}\\nF1 Score={:0.4f}\".format(\n",
        "                accuracy,precision,recall,f1_score)\n",
        "        else:\n",
        "            stats_text = \"\\n\\nAccuracy={:0.4f}\".format(accuracy)\n",
        "    else:\n",
        "        stats_text = \"\"\n",
        "\n",
        "\n",
        "    # SET FIGURE PARAMETERS ACCORDING TO OTHER ARGUMENTS\n",
        "    if figsize==None:\n",
        "        #Get default figure size if not set\n",
        "        figsize = plt.rcParams.get('figure.figsize')\n",
        "\n",
        "    if xyticks==False:\n",
        "        #Do not show categories if xyticks is False\n",
        "        categories=False\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "    ax = plt.figure()\n",
        "\n",
        "    label_font = {'size':'20'}\n",
        "    # MAKE THE HEATMAP VISUALIZATION\n",
        "    plt.figure(figsize=figsize)\n",
        "    sns.set(font_scale=1.5)\n",
        "    sns.heatmap(cf,annot=box_labels,fmt=\"\",cmap=cmap,cbar=cbar,xticklabels=categories,yticklabels=categories)\n",
        "\n",
        "    if xyplotlabels:\n",
        "        plt.ylabel('Predicted label' , fontdict=label_font);\n",
        "        plt.xlabel('True label', fontdict=label_font);\n",
        "        # plt.ylabel('True label')\n",
        "        # plt.xlabel('Predicted label' + stats_text)\n",
        "    else:\n",
        "        plt.xlabel(stats_text)\n",
        "    \n",
        "    if title:\n",
        "        plt.title(title)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "  "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pWDNfSh5gj9c"
      },
      "source": [
        "model=m_aug\n",
        "y_pred = model.predict(x_test) \n",
        "import numpy as np\n",
        "Y_pred = np.argmax(y_pred, 1) \n",
        "Y_test = np.argmax(y_test, 1) "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4Xzxay0dgvL0"
      },
      "source": [
        "\n",
        "mat = sklearn.metrics.confusion_matrix(Y_test, Y_pred) # Confusion matrix\n",
        "lab=['airplane', 'automobile', 'bird', 'cat', 'deer', 'dog', 'frog', 'horse', 'ship', 'truck']"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ly3D5_VOgaBO"
      },
      "source": [
        "make_confusion_matrix(mat,\n",
        "                          group_names=None,\n",
        "                          categories=lab,\n",
        "                          count=False,\n",
        "                          percent=True,\n",
        "                          cbar=True,\n",
        "                          xyticks=True,\n",
        "                          xyplotlabels=True,\n",
        "                          sum_stats=True,\n",
        "                          figsize=(14,14),\n",
        "                          cmap='Blues',\n",
        "                          title=None)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "F_yXGBiQEb_n"
      },
      "source": [
        "from keras.preprocessing import image\n",
        "\n",
        "import random\n",
        "from tensorflow.keras.preprocessing.image import img_to_array, load_img\n",
        "\n",
        "# Get list of layers from model\n",
        "layer_outputs = [layer.output for layer in m_aug.layers[1:]]\n",
        "\n",
        "# Create a visualization model\n",
        "import tensorflow\n",
        "visualize_model = tensorflow.keras.models.Model(inputs = m_aug.input, outputs = layer_outputs)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1EdZOqPLLOfe"
      },
      "source": [
        "# Load image for prediction\n",
        "img=load_img(r'/content/dog1.jpg',target_size=(32,32))\n",
        "\n",
        "# Convert image to array\n",
        "x = img_to_array(img)\n",
        "\n",
        "# Reshape image for passing it to prediction\n",
        "x=x.reshape((1,32,32,3))\n",
        "print(x.shape)\n",
        "# Rescale the image\n",
        "x = x /255\n",
        "\n",
        "# Get all layers feature maps for image\n",
        "feature_maps=visualize_model.predict(x)\n",
        "print(len(feature_maps))\n",
        "\n",
        "# Show names of layers available in model\n",
        "layer_names = [layer.name for layer in model.layers]\n",
        "print(layer_names)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iTEN-cslLxrm"
      },
      "source": [
        "\n",
        "# import required libraries\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline\n",
        "\n",
        "# Plotting the graph\n",
        "for layer_names, feature_maps in zip(layer_names,feature_maps):\n",
        "  print(feature_maps.shape)\n",
        "  if len(feature_maps.shape) == 4 :\n",
        "    channels = feature_maps.shape[-1]\n",
        "    size = feature_maps.shape[1]\n",
        "    display_grid = np.zeros((size, size * channels))\n",
        "    for i in range(channels):\n",
        "      x = feature_maps[0, :, :, i]\n",
        "      x -= x.mean()\n",
        "      x /= x.std()\n",
        "      x *= 64\n",
        "      x += 128\n",
        "      x = np.clip(x, 0, 255).astype('uint8')\n",
        "      # We'll tile each filter into this big horizontal grid\n",
        "      display_grid[:, i * size : (i + 1) * size] = x\n",
        "\n",
        "    scale = 20. / channels\n",
        "    plt.figure(figsize=(scale * channels, scale))\n",
        "    plt.title(layer_names)\n",
        "    plt.grid(False)\n",
        "    plt.imshow(display_grid, aspect='auto', cmap='viridis')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "j7f6iinkHvbJ"
      },
      "source": [
        "# afficher les cannaux \n",
        "img_path = r'/content/dog1.jpg'\n",
        "\n",
        "# We preprocess the image into a 4D tensor\n",
        "from keras.preprocessing import image\n",
        "import numpy as np\n",
        "\n",
        "img = image.load_img(img_path, target_size=(32, 32))\n",
        "img_tensor = image.img_to_array(img)\n",
        "img_tensor = np.expand_dims(img_tensor, axis=0)\n",
        "# Remember that the model was trained on inputs\n",
        "# that were preprocessed in the following way:\n",
        "img_tensor /= 255.\n",
        "\n",
        "# Its shape is (1, 150, 150, 3)\n",
        "print(img_tensor.shape)\n",
        "\n",
        "\n",
        "from keras import models\n",
        "\n",
        "# Extracts the outputs of the top 8 layers:\n",
        "layer_outputs = [layer.output for layer in model.layers[:15]]\n",
        "# Creates a model that will return these outputs, given the model input:\n",
        "activation_model = models.Model(inputs=model.input, outputs=layer_outputs)\n",
        "\n",
        "\n",
        "# one array per layer activation\n",
        "activations = activation_model.predict(img_tensor)\n",
        "   \n",
        "\n",
        "\n",
        "second_layer_activation = activations[13]\n",
        "print(second_layer_activation.shape)\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "plt.matshow(second_layer_activation[0, :, :,10], cmap='viridis')\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VCZWU3ImQWga"
      },
      "source": [
        "first_layer_activation = activations[1]\n",
        "print(second_layer_activation.shape)\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "plt.matshow(first_layer_activation[0, :, :,2], cmap='viridis')\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SZWc9wszHv4G"
      },
      "source": [
        "model.save(\"projet_complet.h5\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gdU4bgTTyoEA"
      },
      "source": [
        "from keras.models import load_model\n",
        "model = load_model(\"projet_complet.h5\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "o_sF7v5Ylu80"
      },
      "source": [
        "import keras\n",
        "\n",
        "# These are the names of the layers, so can have them as part of our plot\n",
        "layer_names = []\n",
        "for layer in model.layers[:15]:\n",
        "    layer_names.append(layer.name)\n",
        "\n",
        "images_per_row = 16\n",
        "\n",
        "# Now let's display our feature maps\n",
        "for layer_name, layer_activation in zip(layer_names, activations):\n",
        "    # This is the number of features in the feature map\n",
        "    n_features = layer_activation.shape[-1]\n",
        "\n",
        "    # The feature map has shape (1, size, size, n_features)\n",
        "    size = layer_activation.shape[1]\n",
        "\n",
        "    # We will tile the activation channels in this matrix\n",
        "    n_cols = n_features // images_per_row\n",
        "    display_grid = np.zeros((size * n_cols, images_per_row * size))\n",
        "\n",
        "    # We'll tile each filter into this big horizontal grid\n",
        "    for col in range(n_cols):\n",
        "        for row in range(images_per_row):\n",
        "            channel_image = layer_activation[0,\n",
        "                                             :, :,\n",
        "                                             col * images_per_row + row]\n",
        "            # Post-process the feature to make it visually palatable\n",
        "            channel_image -= channel_image.mean()\n",
        "            channel_image /= channel_image.std()\n",
        "            channel_image *= 64\n",
        "            channel_image += 128\n",
        "            channel_image = np.clip(channel_image, 0, 255).astype('uint8')\n",
        "            display_grid[col * size : (col + 1) * size,\n",
        "                         row * size : (row + 1) * size] = channel_image\n",
        "\n",
        "    # Display the grid\n",
        "    scale = 1. / size\n",
        "    plt.figure(figsize=(scale * display_grid.shape[1],scale * display_grid.shape[0]))\n",
        "    plt.title(layer_name)\n",
        "    plt.grid(False)\n",
        "    plt.imshow(display_grid, aspect='auto', cmap='viridis')\n",
        "    \n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}